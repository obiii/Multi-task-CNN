{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.models import load_model\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoAddr = '../testVideos/3135.mp4'\n",
    "tempFolder = '../temp'\n",
    "modelPathPFR = '../Models/PFRModel/PFRModel.sav'\n",
    "modelPathFT = '../Models/FuelTypeModel/FTModel.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PFRCLASSES = ['0', '1-3', '10-12', '13-15', '20-25', '30-40', '4-5', '41-56', '6-9', '60+']\n",
    "FTCLASSES = ['20H280NG', 'Ethlyne', 'F1', 'F2', 'NG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPFR(model,image):\n",
    "    # load the input image and then clone it so we can draw on it later\n",
    "    # our model was trained on RGB ordered images but OpenCV represents\n",
    "    # images in BGR order, so swap the channels, and then resize to\n",
    "    # 224x224 (the input dimensions for VGG16)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # convert the image to a floating point data type and perform mean\n",
    "    # subtraction\n",
    "    image = image.astype(\"float32\")\n",
    "    mean = np.array([123.68, 116.779, 103.939][::-1], dtype=\"float32\")\n",
    "    image -= mean\n",
    "    \n",
    "    # pass the image through the network to obtain our predictions\n",
    "    preds = model.predict(np.expand_dims(image, axis=0))[0]\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyFT(model,image):\n",
    "    # load the input image and then clone it so we can draw on it later\n",
    "    # our model was trained on RGB ordered images but OpenCV represents\n",
    "    # images in BGR order, so swap the channels, and then resize to\n",
    "    # 224x224 (the input dimensions for VGG16)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # convert the image to a floating point data type and perform mean\n",
    "    # subtraction\n",
    "    image = image.astype(\"float32\")\n",
    "    mean = np.array([123.68, 116.779, 103.939][::-1], dtype=\"float32\")\n",
    "    image -= mean\n",
    "    \n",
    "    # pass the image through the network to obtain our predictions\n",
    "    preds = model.predict(np.expand_dims(image, axis=0))[0]\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(tempFolder):\n",
    "    os.makedirs(tempFolder)\n",
    "else:\n",
    "    # already exixts, clean it\n",
    "    files = glob.glob(tempFolder+'/*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "import pdb\n",
    "#pdb.set_trace()\n",
    "vidcap = cv2.VideoCapture(videoAddr)\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "\n",
    "print(\"[INFO] loading model...\")\n",
    "#pdb.set_trace()\n",
    "modelPFR = pickle.load(open(modelPathPFR, 'rb'))\n",
    "modelFT = pickle.load(open(modelPathFT, 'rb'))\n",
    "while success:\n",
    "    output = image.copy()\n",
    "    output = imutils.resize(output, width=400)\n",
    "    preds = classifyPFR(modelPFR, image)\n",
    "    ft = classifyFT(modelFT, image)\n",
    "\n",
    "    # draw the prediction on the output image\n",
    "    pfr_i = np.argmax(preds)\n",
    "    ft_i = np.argmax(ft)\n",
    "    pfrlabel = PFRCLASSES[pfr_i]\n",
    "    ftlabel = FTCLASSES[ft_i]\n",
    "    pfrtext = \"PFR - {pfr}: {pfrProb}%\".format(pfr =pfrlabel, pfrProb=np.round(preds[pfr_i] * 100,2))\n",
    "    fttext =  \"Fuel Type - {ft}: {ftProb}%\".format(ft=ftlabel,ftProb=np.round(ft[ft_i]*100,2))\n",
    "    cv2.putText(output, pfrtext, (3, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0, 255, 0), 2)\n",
    "    cv2.putText(output, fttext, (3, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0, 255, 0), 2)\n",
    "    # show the output image\n",
    "    cv2.imshow(\"Output\", output)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    success,image = vidcap.read()\n",
    "    count += 1\n",
    "cv2.destroyWindow('Output') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
